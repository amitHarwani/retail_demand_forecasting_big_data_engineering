version: '3.8'
services:
  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio_data:/data # Persist data in a local volume
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  create_buckets:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set local http://minio:9000 minioadmin minioadmin;
      /usr/bin/mc mb local/raw;
      /usr/bin/mc mb local/refined;
      /usr/bin/mc mb local/curated;
      exit 0;
      "

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Airflow Dockerfile will be built from context (current directory)
  airflow-init:
    build: .
    command: bash -c "airflow db init && airflow users create --username admin --firstname admin --lastname admin --role Admin --email admin@example.com --password admin"
    environment:
      AIRFLOW_CFG_PATH: /opt/airflow/airflow.cfg
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__RBAC: 'true'
      AIRFLOW__WEBSERVER__AUTH_BACKENDS: 'airflow.www.security.authentication.basic_auth'
      # Pass MinIO credentials to Airflow tasks if they use Boto3 directly
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      PG_CONN_STR: postgresql://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./dags:/opt/airflow/dags # Mount local dags directory for scripts to reside
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data # Mount local data directory for scripts to access
      - ./models:/opt/airflow/models # Mount local models directory
      - ./forecasts:/opt/airflow/forecasts # Mount local forecasts directory
    depends_on:
      postgres:
        condition: service_healthy

  airflow-webserver:
    build: .
    command: airflow webserver
    ports:
      - "8080:8080"
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__RBAC: 'true'
      AIRFLOW__WEBSERVER__AUTH_BACKENDS: 'airflow.www.security.authentication.basic_auth'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data # Mount local data directory
      - ./models:/opt/airflow/models # Mount local models directory
      - ./forecasts:/opt/airflow/forecasts # Mount local forecasts directory
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    build: .
    command: airflow scheduler
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data # Mount local data directory
      - ./models:/opt/airflow/models # Mount local models directory
      - ./forecasts:/opt/airflow/forecasts # Mount local forecasts directory
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  model_serving:
    build: . # Uses the same Dockerfile to build for model serving
    command: python /opt/airflow/dags/model_serving.py # Path inside container
    ports:
      - "5000:5000" # Expose Flask app port
    environment:
      MINIO_ENDPOINT: http://minio:9000 # Use 'minio' as service name for inter-container communication
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    volumes:
      - ./dags:/opt/airflow/dags # To access model_serving.py and its dependencies
      - ./models:/opt/airflow/models # To store/load models locally in container
      - ./data:/opt/airflow/data # For static metadata files used by the endpoint (e.g., catalog.csv, stores.csv)
    depends_on:
      minio:
        condition: service_healthy # Model server needs MinIO to load model
      airflow-init: # Wait for Airflow init to ensure model is trained and uploaded
        condition: service_completed_successfully


  superset:
    image: apache/superset:latest
    container_name: superset_app
    environment:
      SUPERSET_SECRET_KEY: a_very_secret_key_for_superset # IMPORTANT: Change this!
      FLASK_APP: superset
      SUPERSET_WEBSERVER_TIMEOUT: 600
    ports:
      - "8088:8088"
    volumes:
      - ./superset_home:/app/superset_home
    command: ["/bin/bash", "-c", "superset db upgrade && superset init && superset run -h 0.0.0.0 -p 8088 --with-threads --reload --debugger"]
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  superset-worker:
    image: apache/superset:latest
    container_name: superset_worker
    environment:
      SUPERSET_SECRET_KEY: a_very_secret_key_for_superset # IMPORTANT: Change this!
      FLASK_APP: superset
      SUPERSET_WEBSERVER_TIMEOUT: 600
    volumes:
      - ./superset_home:/app/superset_home
    command: ["superset", "celery", "worker"]
    depends_on:
      superset:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  superset-init:
    image: apache/superset:latest
    container_name: superset_init
    entrypoint: /bin/bash -c "sleep 10 && superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin || true"
    depends_on:
      superset:
        condition: service_healthy

volumes:
  minio_data:
  superset_home:
