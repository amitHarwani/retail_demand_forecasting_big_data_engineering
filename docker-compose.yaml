services:
  minio: # minio for S3 Compatible Storage
    image: minio/minio # minio Image
    ports:
      - "9000:9000" # API
      - "9001:9001" # Web console
    volumes:
      - ./minio_data:/data # (Bind Mount)   Persist data in a local volume - minio_data folder in local machine
    environment: # Environment variables for username and password
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001" # After the container starts, start the minio server, serving the data folder and web console on port 9001
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 5s

  create_buckets: # To create the three buckets initially
    image: minio/mc # Minio client image - For interacting with object storage with unix commands
    depends_on: # Start this service only after minio service is running
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set local http://minio:9000 minioadmin minioadmin;
      /usr/bin/mc mb local/raw;
      /usr/bin/mc mb local/transformed;
      /usr/bin/mc mb local/forecasts;
      exit 0;
      "
  spark-client:
    build: . # Build from the Dockerfile
    entrypoint: ["sleep", "infinity"] # Keep the container running indefinitely to run spark jobs
    environment: # Enviornment variables: minio endpoint and credentials
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      # Set Spark environment variables if needed, though usually configs in script are enough
      # Configures PySpark (the Python interface to Spark) to include two key packages
      # enables spark to work with Object Storage, 
      PYSPARK_SUBMIT_ARGS: "--packages org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.11.901 pyspark-shell"
    volumes:
      - ./dags:/opt/airflow/dags # Mount your dags folder to access scripts
      - ./data:/opt/airflow/data # For local data files like split/sales_ingest_sim.csv
      - ./models:/opt/airflow/models # To access locally downloaded models (if needed)
      - ./forecasts:/opt/airflow/forecasts # To see local forecast outputs (if scripts write locally)
    depends_on:
      minio:
        condition: service_healthy

  postgres:
    image: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    volumes:
      - ./initdb:/docker-entrypoint-initdb.d
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U demand_forecast"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Airflow Dockerfile will be built from context (current directory)
  # Initializes the Airflow database and create an admin user.
  airflow-init:
    build: .
    command: bash -c "airflow db init && airflow users create --username admin --firstname admin --lastname admin --role Admin --email admin@example.com --password admin"
    environment:
      AIRFLOW_CFG_PATH: /opt/airflow/airflow.cfg
      AIRFLOW_HOME: /opt/airflow # Airflow Installation dir
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags # Where to find the DAGS
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false' # Turn off sample workflows
      AIRFLOW__CORE__EXECUTOR: LocalExecutor # Local execution
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://demand_forecast:demand_forecast@postgres/demand_forecast # Database for airflow to store its metadata
      AIRFLOW__WEBSERVER__RBAC: 'true' # For basic login into the web UI
      AIRFLOW__WEBSERVER__AUTH_BACKENDS: 'airflow.www.security.authentication.basic_auth' # For basic login into the web UI
      # Pass MinIO credentials to Airflow tasks
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      PG_CONN_STR: postgresql://demand_forecast:demand_forecast@postgres:5432/demand_forecast # For storing forecasts in postgres
    volumes:
      - ./dags:/opt/airflow/dags # Mount local dags directory for scripts to reside
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data # Mount local data directory for scripts to access
      - ./models:/opt/airflow/models # Mount local models directory
      - ./forecasts:/opt/airflow/forecasts # Mount local forecasts directory
    depends_on:
      postgres:
        condition: service_healthy

  # Hosts the airflow web server
  airflow-webserver:
    build: .
    command: airflow webserver
    ports:
      - "8080:8080"
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://demand_forecast:demand_forecast@postgres/demand_forecast
      AIRFLOW__WEBSERVER__RBAC: 'true'
      AIRFLOW__WEBSERVER__AUTH_BACKENDS: 'airflow.www.security.authentication.basic_auth'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data # Mount local data directory
      - ./models:/opt/airflow/models # Mount local models directory
      - ./forecasts:/opt/airflow/forecasts # Mount local forecasts directory
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  # Continuously looks for DAGs that need to be run (based on schedules) and kicks off their tasks.
  airflow-scheduler:
    build: .
    command: airflow scheduler
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://demand_forecast:demand_forecast@postgres/demand_forecast
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data # Mount local data directory
      - ./models:/opt/airflow/models # Mount local models directory
      - ./forecasts:/opt/airflow/forecasts # Mount local forecasts directory
    depends_on:
      airflow-init:
        condition: service_completed_successfully
  
  redis:
    image: redis:6
    container_name: superset_redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  superset:
    image: apache/superset
    container_name: superset_app
    environment:
      # Metadata DB
      DATABASE_URL: postgresql+psycopg2://demand_forecast:demand_forecast@postgres/superset
      # Caching & broker
      REDIS_URL: redis://redis:6379/0
      # Flask 
      SUPERSET_SECRET_KEY: 4a2ec4bb1554c346570e9212739f38e773365512f7b978ea2d698291fe5fbab1 
      FLASK_APP: superset
      SUPERSET_WEBSERVER_TIMEOUT: 600 # HTTP Request timeout
    ports:
      - "8088:8088"
    volumes:
      - ./superset_home:/app/superset_home
    command: ["/bin/bash", "-c", "superset db upgrade && superset init && superset run -h 0.0.0.0 -p 8088 --with-threads"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8088/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Runs asynchronous jobs (e.g., caching charts, running slow queries in the background.) via Celery.
  # Superset (web server) is the producer — it puts task messages on Redis
  # Superset Worker is the consumer — it listens for tasks on Redis and runs them
  superset-worker:
    image: apache/superset
    container_name: superset_worker
    environment:
      DATABASE_URL: postgresql+psycopg2://demand_forecast:demand_forecast@postgres/superset
      REDIS_URL: redis://redis:6379/0
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
      SUPERSET_SECRET_KEY: 4a2ec4bb1554c346570e9212739f38e773365512f7b978ea2d698291fe5fbab1
      FLASK_APP: superset
      SUPERSET_WEBSERVER_TIMEOUT: 600
    volumes:
      - ./superset_home:/app/superset_home
    command: ["celery", "--app=superset.tasks.celery_app:app", "worker", "-l", "info"]
    depends_on:
      superset:
        condition: service_healthy

  # After the web app is up, create an admin user for Superset.
  superset-init:
    image: apache/superset
    container_name: superset_init
    environment:
      DATABASE_URL: postgresql+psycopg2://demand_forecast:demand_forecast@postgres/superset
      REDIS_URL: redis://redis:6379/0
      FLASK_APP: superset
      SUPERSET_SECRET_KEY: 4a2ec4bb1554c346570e9212739f38e773365512f7b978ea2d698291fe5fbab1
    volumes:
      - ./superset_home:/app/superset_home
    entrypoint:
      - /bin/bash
      - -c
      - |
        echo "Waiting for Superset to be healthy..."
        until curl -sf http://superset:8088/health; do
          sleep 2
        done

        echo "Creating admin user..."
        superset fab create-admin \
        --username admin \
        --firstname Superset \
        --lastname Admin \
        --email admin@superset.com \
        --password admin \
        || true
    depends_on:
      superset:
        condition: service_healthy
  
volumes:
  postgres-data: